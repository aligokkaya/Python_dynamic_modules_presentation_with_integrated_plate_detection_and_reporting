<!doctype html>
<html lang="en">
<head>
<meta charset="utf-8">
<meta name="viewport" content="width=device-width, initial-scale=1, minimum-scale=1" />
<meta name="generator" content="pdoc 0.9.2" />
<title>HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract API documentation</title>
<meta name="description" content="" />
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/sanitize.min.css" integrity="sha256-PK9q560IAAa6WVRRh76LtCaI8pjTJ2z11v0miyNNjrs=" crossorigin>
<link rel="preload stylesheet" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/10up-sanitize.css/11.0.1/typography.min.css" integrity="sha256-7l/o7C8jubJiy74VsKTidCy1yBkRtiUGbVkYBylBqUg=" crossorigin>
<link rel="stylesheet preload" as="style" href="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/styles/github.min.css" crossorigin>
<style>:root{--highlight-color:#fe9}.flex{display:flex !important}body{line-height:1.5em}#content{padding:20px}#sidebar{padding:30px;overflow:hidden}#sidebar > *:last-child{margin-bottom:2cm}.http-server-breadcrumbs{font-size:130%;margin:0 0 15px 0}#footer{font-size:.75em;padding:5px 30px;border-top:1px solid #ddd;text-align:right}#footer p{margin:0 0 0 1em;display:inline-block}#footer p:last-child{margin-right:30px}h1,h2,h3,h4,h5{font-weight:300}h1{font-size:2.5em;line-height:1.1em}h2{font-size:1.75em;margin:1em 0 .50em 0}h3{font-size:1.4em;margin:25px 0 10px 0}h4{margin:0;font-size:105%}h1:target,h2:target,h3:target,h4:target,h5:target,h6:target{background:var(--highlight-color);padding:.2em 0}a{color:#058;text-decoration:none;transition:color .3s ease-in-out}a:hover{color:#e82}.title code{font-weight:bold}h2[id^="header-"]{margin-top:2em}.ident{color:#900}pre code{background:#f8f8f8;font-size:.8em;line-height:1.4em}code{background:#f2f2f1;padding:1px 4px;overflow-wrap:break-word}h1 code{background:transparent}pre{background:#f8f8f8;border:0;border-top:1px solid #ccc;border-bottom:1px solid #ccc;margin:1em 0;padding:1ex}#http-server-module-list{display:flex;flex-flow:column}#http-server-module-list div{display:flex}#http-server-module-list dt{min-width:10%}#http-server-module-list p{margin-top:0}.toc ul,#index{list-style-type:none;margin:0;padding:0}#index code{background:transparent}#index h3{border-bottom:1px solid #ddd}#index ul{padding:0}#index h4{margin-top:.6em;font-weight:bold}@media (min-width:200ex){#index .two-column{column-count:2}}@media (min-width:300ex){#index .two-column{column-count:3}}dl{margin-bottom:2em}dl dl:last-child{margin-bottom:4em}dd{margin:0 0 1em 3em}#header-classes + dl > dd{margin-bottom:3em}dd dd{margin-left:2em}dd p{margin:10px 0}.name{background:#eee;font-weight:bold;font-size:.85em;padding:5px 10px;display:inline-block;min-width:40%}.name:hover{background:#e0e0e0}dt:target .name{background:var(--highlight-color)}.name > span:first-child{white-space:nowrap}.name.class > span:nth-child(2){margin-left:.4em}.inherited{color:#999;border-left:5px solid #eee;padding-left:1em}.inheritance em{font-style:normal;font-weight:bold}.desc h2{font-weight:400;font-size:1.25em}.desc h3{font-size:1em}.desc dt code{background:inherit}.source summary,.git-link-div{color:#666;text-align:right;font-weight:400;font-size:.8em;text-transform:uppercase}.source summary > *{white-space:nowrap;cursor:pointer}.git-link{color:inherit;margin-left:1em}.source pre{max-height:500px;overflow:auto;margin:0}.source pre code{font-size:12px;overflow:visible}.hlist{list-style:none}.hlist li{display:inline}.hlist li:after{content:',\2002'}.hlist li:last-child:after{content:none}.hlist .hlist{display:inline;padding-left:1em}img{max-width:100%}td{padding:0 .5em}.admonition{padding:.1em .5em;margin-bottom:1em}.admonition-title{font-weight:bold}.admonition.note,.admonition.info,.admonition.important{background:#aef}.admonition.todo,.admonition.versionadded,.admonition.tip,.admonition.hint{background:#dfd}.admonition.warning,.admonition.versionchanged,.admonition.deprecated{background:#fd4}.admonition.error,.admonition.danger,.admonition.caution{background:lightpink}</style>
<style media="screen and (min-width: 700px)">@media screen and (min-width:700px){#sidebar{width:30%;height:100vh;overflow:auto;position:sticky;top:0}#content{width:70%;max-width:100ch;padding:3em 4em;border-left:1px solid #ddd}pre code{font-size:1em}.item .name{font-size:1em}main{display:flex;flex-direction:row-reverse;justify-content:flex-end}.toc ul ul,#index ul{padding-left:1.5em}.toc > ul > li{margin-top:.5em}}</style>
<style media="print">@media print{#sidebar h1{page-break-before:always}.source{display:none}}@media print{*{background:transparent !important;color:#000 !important;box-shadow:none !important;text-shadow:none !important}a[href]:after{content:" (" attr(href) ")";font-size:90%}a[href][title]:after{content:none}abbr[title]:after{content:" (" attr(title) ")"}.ir a:after,a[href^="javascript:"]:after,a[href^="#"]:after{content:""}pre,blockquote{border:1px solid #999;page-break-inside:avoid}thead{display:table-header-group}tr,img{page-break-inside:avoid}img{max-width:100% !important}@page{margin:0.5cm}p,h2,h3{orphans:3;widows:3}h1,h2,h3,h4,h5,h6{page-break-after:avoid}}</style>
<script defer src="https://cdnjs.cloudflare.com/ajax/libs/highlight.js/10.1.1/highlight.min.js" integrity="sha256-Uv3H6lx7dJmRfRvH8TH6kJD1TSK1aFcwgx+mdg3epi8=" crossorigin></script>
<script>window.addEventListener('DOMContentLoaded', () => hljs.initHighlighting())</script>
</head>
<body>
<main>
<article id="content">
<header>
<h1 class="title">Module <code>HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract</code></h1>
</header>
<section id="section-intro">
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">import subprocess
import time

from utils import Statics
import itertools
import os
import platform
import lsb_release
from subprocess import STDOUT, check_call
from timeit import default_timer as timer
import cv2
import pytesseract
import matplotlib.pyplot as plt
import numpy as np
from PIL import Image as im
from scipy.ndimage import interpolation as inter
import re
import string

from utils.UtilsGeneric import image_resize, clear_text


class TestTesseract:
    &#34;&#34;&#34;
            ATTENTION !! THIS MODULE ONLY WORKS ON DEBIAN BASED SYSTEMS
            sudo add-apt-repository ppa:alex-p/tesseract-ocr
            sudo apt-get update
            sudo apt install tesseract-ocr

            If you wish to run this code on a raspberry or arm systems.. you should COMPILE !!

            This Module uses base tesseract methods to determine texts on a image..
            Tesseract is around for a very long period of time..
            we even manage to convert HANDWRITTEN OTTOMAN Language to digital texts.
            Unfortunately this module REQUIRES PROPER dataset and training..
            as long as you have a clean dataset you will get min %95 success ratio.
            for plate recognition this model is too expensive..
            but the idea about it is the same if you have a very competitive company against you..
            this should be the way you follow to showoff the difference in engineering  quality..


        &#34;&#34;&#34;
    pytesseract.pytesseract.tesseract_cmd = &#39;tesseract&#39;
    base_img=None
    prepared_img=None
    prepare_start_time=None
    prepare_end_time=None
    start_time=None
    end_time=None
    each_img_process_time= {}

    run =1
    using_gpu = 0
    my_info = {}
    model_usage = 0
    mymodels = []
    retrain = 0
    newlinux=0

    min_confidence = 0.5
    default_width = 320
    default_height = 320
    rW = 0
    rH = 0
    MY_RESULTS = {}
    def __init__(self, model_usage=0):

        self.model_usage = model_usage

        self.my_info[&#34;name&#34;] = self.__class__
        self.my_info[&#34;using_gpu&#34;] = self.using_gpu
        self.my_info[&#34;module_presentation&#34;] = self.__doc__
        self.my_info[&#34;used models&#34;] = self.mymodels


    def return_my_dict(self):
        return self.my_info

    def return_dict_with_results(self):
        return self.my_info

    def check_deps(self):
        # first check version of linux.
        str = lsb_release.get_lsb_information()
        release=str[&#34;RELEASE&#34;]
        if release.startswith(&#34;18&#34;) or release.starsWith(&#34;19&#34;) or release.startsWith(&#34;20&#34;):
            self.newlinux=1
        # first check if tesseract is installed..
        return_data=&#34;&#34;
        try_to_install=0
        try :
            result = subprocess.run([&#39;tesseract&#39;, &#39;-v&#39;], stdout=subprocess.PIPE)
            return_data=result.stdout
            if return_data.find(&#34;not found&#34;) &gt; -1 or return_data.find(&#34;No such file or directory&#34;) &gt; -1 :
                try_to_install=1
        except:
            try_to_install=1

        if try_to_install == 1 :
            # tesseract is not installed
            if self.newlinux == 1:
                # can install with apt-get
                check_call([&#39;apt-get&#39;, &#39;install&#39;, &#39;-y&#39;, &#39;tesseract-ocr&#39;],
                           stdout=open(os.devnull, &#39;wb&#39;), stderr=STDOUT)
            else :
                check_call([ &#39;add-apt-repository&#39;,  &#39;-y&#39;, &#39;ppa:alex-p/tesseract-ocr&#39;],
                           stdout=open(os.devnull, &#39;wb&#39;), stderr=STDOUT)
                check_call([ &#39;apt-get&#39;, &#39;update&#39;],
                           stdout=open(os.devnull, &#39;wb&#39;), stderr=STDOUT)
                check_call([ &#39;apt-get&#39;, &#39;install&#39;, &#39;-y&#39;, &#39;tesseract-ocr&#39;],
                           stdout=open(os.devnull, &#39;wb&#39;), stderr=STDOUT)
        try:
            output_folder_name = &#39;INPUT_OUTPUT/outputs/&#39; + str(self.__class__.__name__)
            os.makedirs(output_folder_name)
        except OSError as e:
            Statics.LOGGER.logme(str(self.__class__.__name__)+&#34; &#34;+str(e))
    def start_main_timer(self):
        start = timer()
        self.start_time = start
        self.MY_RESULTS[&#34;main_timer_start&#34;] = start

    def end_main_timer(self):
        end = timer()
        self.end_time = end
        self.MY_RESULTS[&#34;main_timer_end&#34;] = end

    def prepare_img(self, imgx):
        self.each_img_process_time[imgx] = {}
        self.MY_RESULTS[imgx] = {}
        start1 = timer()
        self.each_img_process_time[imgx][&#34;prepare_start_&#34;] = start1
        self.MY_RESULTS[imgx][&#34;prepare_start_&#34;] = start1
        # process
        img = cv2.imread(imgx)
        self.base_img = cv2.imread(imgx)
        orig = self.base_img.copy()
        # image_resized = cv2.resize(orig,width=320,interpolation=cv2.INTER_CUBIC)
        image_resized =  image_resize(orig, width=320)
        (H, W) = image_resized.shape[:2]

        # set the new width and height and then determine the ratio in change
        # for both the width and height
        blank_image = cv2.fastNlMeansDenoisingColored(image_resized, None, 10, 10, 7, 21)
        # blank_image= cv2.adaptiveThreshold(blank_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)
        img_gray = cv2.cvtColor(blank_image, cv2.COLOR_BGR2GRAY)
        img_blur = cv2.medianBlur(img_gray, 5)
        img_thresh_Gaussian = cv2.adaptiveThreshold(img_blur, 255,
                                                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
        (thresh, blackAndWhiteImage) = cv2.threshold(img_thresh_Gaussian, 127, 255, cv2.THRESH_BINARY)

        # kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
        # self.prepared_img = cv2.filter2D(blank_image, -1, kernel)
        # self.prepared_img = cv2.cvtColor(self.prepared_img, cv2.COLOR_BGR2GRAY)

        fake_rgb = cv2.cvtColor(blackAndWhiteImage, cv2.COLOR_GRAY2RGB)
        copyx = fake_rgb.copy()
        fake_gray = cv2.cvtColor(copyx, cv2.COLOR_BGR2GRAY)
        contours, hier = cv2.findContours(fake_gray, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        blank_image2 = np.zeros((H, W, 3), np.uint8)

        blank_image2[:, :] = (255, 255, 255)
        blank_image3 = np.zeros((H, W, 3), np.uint8)

        blank_image3[:, :] = (255, 255, 255)
        # we are going to use a simple trick in there ...
        # if we know the font then it will be alot easier to calculate and get the contour according to font aspect ratio..
        # but it is a little messy..
        # so.. LETS take a ratio where our value is the overall ratio of common fonts..
        &#34;&#34;&#34;Arial        0.52
            Avant Garde         0.45
            Bookman     0.40
            Calibri     0.47
            Century Schoolbook  0.48
            Cochin      0.41
            Comic Sans  0.53
            Courier     0.43
            Courier New         0.42
            Garamond    0.38
            Georgia     0.48
            Helvetica   0.52
            Palatino    0.42
            Tahoma      0.55
            Times New Roman     0.45
            Trebuchet   0.52
            Verdana     0.58
            ------------------------------------
            W is messing with the calculations.. but wahtsoever.. their average is 0.471176470588235
            so it is 0,472
            but we are not looking all plates with birds eye.. and some of them are really messy..
             
            lets assume we are alooking with 45 degree.. (simple opengl calculations..) i m not forcing these calculations
            to be taken with all possible scenarios.. i m just calculating for 2 scenarios where width and height alone can change alot.. 
            then our 0.472 can become -&gt; w=472 h=1000 
                                            =&gt; rectangular area Height will increase 1000+472÷√2=1333,75
                                            =&gt; rectangular area WIDTH will drop to 472÷√2=333.75
                                            =&gt; so our 0.472 will become 0.25
            lets assume we are looking from a higher place where Height will look smaller.. lets assume again 45 degrees
                                        -&gt; w=472  h=1000
                                            =&gt; this time width will stay same..   472
                                            =&gt; heigh will change Angle ∠A = 22.5° = 22°30&#39;0&#34; = 0.3927 rad = π/8
                                                                Angle ∠B = 22.5° = 22°30&#39;0&#34; = 0.3927 rad = π/8
                                                                Angle ∠C = 135° = 2.35619 rad = 3/4π 
                                                                Side a = 541.1961
                                                                Side b = 541.1961
                                                                Side c = 1,000
                                                                
                                                                So our 0.472 will become to 472/541.19 =0.872
            so we will use 0.25 to 0.872
            -&gt; we should consider 1 more thing. first countours are not perfect because whatever we do to increase image quality there will be always nested contours
            or multiple chars to be accepted as one.. 
            so =&gt; first get image width into consideration.. with maximum minimum char count.. and find a proper orientation between them and newly calculated averages
            
            
            
            
            height/wiodth ratio
    ATTENTION !! this paart should be calculated with lots of samples.. in order to see perfect ratio
            
        
        &#34;&#34;&#34;

        for cnt in contours:
            if 200 &lt; cv2.contourArea(cnt) &lt; 5000:
                cv2.drawContours(self.prepared_img, [cnt], 0, (0, 255, 0), 2)
                cv2.drawContours(self.prepared_img, [cnt], 0, 255, -1)
                cv2.drawContours(fake_gray, [cnt], 0, (0, 255, 0), 2)
                cv2.drawContours(fake_gray, [cnt], 0, 255, -1)
                x, y, w, h = cv2.boundingRect(cnt)
                ROI = fake_rgb[y:y + h, x:x + w]
                cloneimg = ROI.copy()
                blank_image2[y:y + h, x:x + w] = cloneimg
        average_min=0.25
        average_max=0.872

        for cnt in contours:
            x, y, w, h = cv2.boundingRect(cnt)
            average = w/h


            if average_min &lt;= average &lt;= average_max :
                ROI = fake_rgb[y:y + h, x:x + w]
                cloneimg = ROI.copy()
                blank_image3[y:y + h, x:x + w] = cloneimg

        cv2.imwrite(&#34;/tmp/blank_image3&#34; + str(round(time.time() * 1000)) + &#34;.jpg&#34;, blank_image3)
        cv2.imwrite(&#34;/tmp/blank_image2&#34; + str(round(time.time() * 1000)) + &#34;.jpg&#34;, blank_image2)
        self.prepared_img = blank_image3

        self.base_img = img

        end1 = timer()
        self.each_img_process_time[imgx][&#34;prepare_end_&#34;] = end1
        self.MY_RESULTS[imgx][&#34;prepare_end_&#34;] = end1
    def prepareold_img(self,imgx):
        self.each_img_process_time[imgx] = {}
        start1 = timer()
        self.each_img_process_time[imgx][&#34;prepare_start_&#34;]=start1
        # process
        img = cv2.imread(imgx)

        #now try to resize ... remove noise...
        resize_test_license_plate = cv2.resize(
            img, None, fx=2, fy=2,
            interpolation=cv2.INTER_CUBIC)

        grayscale_resize_test_license_plate = cv2.cvtColor(
            resize_test_license_plate, cv2.COLOR_BGR2GRAY)

        gaussian_blur_license_plate = cv2.GaussianBlur(
            grayscale_resize_test_license_plate, (5, 5), 0)
        ret, imgf = cv2.threshold(gaussian_blur_license_plate, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
        gray = cv2.medianBlur(imgf, 3)
        imgf = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)


        self.prepared_img = imgf
        self.base_img=img

        end1 = timer()
        self.each_img_process_time[imgx][&#34;prepare_end&#34;] =end1

    def prepare(self):
        start = timer()
        self.prepare_start_time = start
        self.MY_RESULTS[&#34;prepare_start&#34;] = start

        end = timer()
        self.prepare_end_time = end
        self.MY_RESULTS[&#34;prepare_end&#34;] = end

    def start_(self, imgx):
        start1 = timer()
        self.each_img_process_time[imgx][&#34;_start&#34;] = start1
        self.MY_RESULTS[imgx][&#34;_start&#34;] = start1
        # process
        base2 = self.base_img.copy()
        hsv = cv2.cvtColor(base2, cv2.COLOR_BGR2HSV)
        lower = np.array(np.array([0,0,0], dtype=np.uint8), dtype=&#34;uint8&#34;)
        upper = np.array(np.array([0,0,255], dtype=np.uint8), dtype=&#34;uint8&#34;)

        # find the colors within the specified boundaries and apply
        # the mask
        mask = cv2.inRange(hsv, lower, upper)
        output = cv2.bitwise_and(base2, base2, mask=mask)

        ret, thresh = cv2.threshold(mask, 40, 255, 0)
        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

        if len(contours) != 0:
            # draw in blue the contours that were founded
            cv2.drawContours(output, contours, -1, 255, 3)

            # find the biggest countour (c) by the area
            c = max(contours, key=cv2.contourArea)
            x, y, w, h = cv2.boundingRect(c)

            # draw the biggest contour (c) in green
            cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 2)

        #cv2.imwrite(imgx.replace(&#39;/img/&#39;,(&#39;/outputs/&#39;+str(self.my_info[&#34;name&#34;]))+&#34;/&#34;),output)
        predicted_result = pytesseract.image_to_string(self.prepared_img, lang=&#39;eng&#39;,
                                                       config=&#39;--oem 1 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&#39;)

        filter_predicted_result = &#34;&#34;.join(predicted_result.split()).replace(&#34;:&#34;, &#34;&#34;).replace(&#34;-&#34;, &#34;&#34;).replace(&#34;_&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
        cleared_text = clear_text(filter_predicted_result)
        self.MY_RESULTS[imgx][&#34;result&#34;] = cleared_text
        self.MY_RESULTS[imgx][&#34;dirty_result&#34;] = filter_predicted_result

        #print(imgx + &#34; -&gt; &#34; + pytesseract.image_to_string(self.prepared_img))
        cv2.imwrite(imgx.replace(&#39;/img/&#39;, (&#39;/outputs/&#39; + str(self.my_info[&#34;name&#34;])) + &#34;/&#34;), output)
        Statics.LOGGER.logme(str(self.__class__.__name__)+&#34; &#34;+imgx+ &#34; -&gt; &#34;+filter_predicted_result)

        end1 = timer()
        self.each_img_process_time[imgx][&#34;_end&#34;] = end1
        self.MY_RESULTS[imgx][&#34;_end&#34;] = end1



    def find_score(self, arr, angle):
        data = inter.rotate(arr, angle, reshape=False, order=0)
        hist = np.sum(data, axis=1)
        score = np.sum((hist[1:] - hist[:-1]) ** 2)
        return hist,  1</code></pre>
</details>
</section>
<section>
</section>
<section>
</section>
<section>
</section>
<section>
<h2 class="section-title" id="header-classes">Classes</h2>
<dl>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract"><code class="flex name class">
<span>class <span class="ident">TestTesseract</span></span>
<span>(</span><span>model_usage=0)</span>
</code></dt>
<dd>
<div class="desc"><p>ATTENTION !! THIS MODULE ONLY WORKS ON DEBIAN BASED SYSTEMS
sudo add-apt-repository ppa:alex-p/tesseract-ocr
sudo apt-get update
sudo apt install tesseract-ocr</p>
<p>If you wish to run this code on a raspberry or arm systems.. you should COMPILE !!</p>
<p>This Module uses base tesseract methods to determine texts on a image..
Tesseract is around for a very long period of time..
we even manage to convert HANDWRITTEN OTTOMAN Language to digital texts.
Unfortunately this module REQUIRES PROPER dataset and training..
as long as you have a clean dataset you will get min %95 success ratio.
for plate recognition this model is too expensive..
but the idea about it is the same if you have a very competitive company against you..
this should be the way you follow to showoff the difference in engineering
quality..</p></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">class TestTesseract:
    &#34;&#34;&#34;
            ATTENTION !! THIS MODULE ONLY WORKS ON DEBIAN BASED SYSTEMS
            sudo add-apt-repository ppa:alex-p/tesseract-ocr
            sudo apt-get update
            sudo apt install tesseract-ocr

            If you wish to run this code on a raspberry or arm systems.. you should COMPILE !!

            This Module uses base tesseract methods to determine texts on a image..
            Tesseract is around for a very long period of time..
            we even manage to convert HANDWRITTEN OTTOMAN Language to digital texts.
            Unfortunately this module REQUIRES PROPER dataset and training..
            as long as you have a clean dataset you will get min %95 success ratio.
            for plate recognition this model is too expensive..
            but the idea about it is the same if you have a very competitive company against you..
            this should be the way you follow to showoff the difference in engineering  quality..


        &#34;&#34;&#34;
    pytesseract.pytesseract.tesseract_cmd = &#39;tesseract&#39;
    base_img=None
    prepared_img=None
    prepare_start_time=None
    prepare_end_time=None
    start_time=None
    end_time=None
    each_img_process_time= {}

    run =1
    using_gpu = 0
    my_info = {}
    model_usage = 0
    mymodels = []
    retrain = 0
    newlinux=0

    min_confidence = 0.5
    default_width = 320
    default_height = 320
    rW = 0
    rH = 0
    MY_RESULTS = {}
    def __init__(self, model_usage=0):

        self.model_usage = model_usage

        self.my_info[&#34;name&#34;] = self.__class__
        self.my_info[&#34;using_gpu&#34;] = self.using_gpu
        self.my_info[&#34;module_presentation&#34;] = self.__doc__
        self.my_info[&#34;used models&#34;] = self.mymodels


    def return_my_dict(self):
        return self.my_info

    def return_dict_with_results(self):
        return self.my_info

    def check_deps(self):
        # first check version of linux.
        str = lsb_release.get_lsb_information()
        release=str[&#34;RELEASE&#34;]
        if release.startswith(&#34;18&#34;) or release.starsWith(&#34;19&#34;) or release.startsWith(&#34;20&#34;):
            self.newlinux=1
        # first check if tesseract is installed..
        return_data=&#34;&#34;
        try_to_install=0
        try :
            result = subprocess.run([&#39;tesseract&#39;, &#39;-v&#39;], stdout=subprocess.PIPE)
            return_data=result.stdout
            if return_data.find(&#34;not found&#34;) &gt; -1 or return_data.find(&#34;No such file or directory&#34;) &gt; -1 :
                try_to_install=1
        except:
            try_to_install=1

        if try_to_install == 1 :
            # tesseract is not installed
            if self.newlinux == 1:
                # can install with apt-get
                check_call([&#39;apt-get&#39;, &#39;install&#39;, &#39;-y&#39;, &#39;tesseract-ocr&#39;],
                           stdout=open(os.devnull, &#39;wb&#39;), stderr=STDOUT)
            else :
                check_call([ &#39;add-apt-repository&#39;,  &#39;-y&#39;, &#39;ppa:alex-p/tesseract-ocr&#39;],
                           stdout=open(os.devnull, &#39;wb&#39;), stderr=STDOUT)
                check_call([ &#39;apt-get&#39;, &#39;update&#39;],
                           stdout=open(os.devnull, &#39;wb&#39;), stderr=STDOUT)
                check_call([ &#39;apt-get&#39;, &#39;install&#39;, &#39;-y&#39;, &#39;tesseract-ocr&#39;],
                           stdout=open(os.devnull, &#39;wb&#39;), stderr=STDOUT)
        try:
            output_folder_name = &#39;INPUT_OUTPUT/outputs/&#39; + str(self.__class__.__name__)
            os.makedirs(output_folder_name)
        except OSError as e:
            Statics.LOGGER.logme(str(self.__class__.__name__)+&#34; &#34;+str(e))
    def start_main_timer(self):
        start = timer()
        self.start_time = start
        self.MY_RESULTS[&#34;main_timer_start&#34;] = start

    def end_main_timer(self):
        end = timer()
        self.end_time = end
        self.MY_RESULTS[&#34;main_timer_end&#34;] = end

    def prepare_img(self, imgx):
        self.each_img_process_time[imgx] = {}
        self.MY_RESULTS[imgx] = {}
        start1 = timer()
        self.each_img_process_time[imgx][&#34;prepare_start_&#34;] = start1
        self.MY_RESULTS[imgx][&#34;prepare_start_&#34;] = start1
        # process
        img = cv2.imread(imgx)
        self.base_img = cv2.imread(imgx)
        orig = self.base_img.copy()
        # image_resized = cv2.resize(orig,width=320,interpolation=cv2.INTER_CUBIC)
        image_resized =  image_resize(orig, width=320)
        (H, W) = image_resized.shape[:2]

        # set the new width and height and then determine the ratio in change
        # for both the width and height
        blank_image = cv2.fastNlMeansDenoisingColored(image_resized, None, 10, 10, 7, 21)
        # blank_image= cv2.adaptiveThreshold(blank_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)
        img_gray = cv2.cvtColor(blank_image, cv2.COLOR_BGR2GRAY)
        img_blur = cv2.medianBlur(img_gray, 5)
        img_thresh_Gaussian = cv2.adaptiveThreshold(img_blur, 255,
                                                    cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
        (thresh, blackAndWhiteImage) = cv2.threshold(img_thresh_Gaussian, 127, 255, cv2.THRESH_BINARY)

        # kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
        # self.prepared_img = cv2.filter2D(blank_image, -1, kernel)
        # self.prepared_img = cv2.cvtColor(self.prepared_img, cv2.COLOR_BGR2GRAY)

        fake_rgb = cv2.cvtColor(blackAndWhiteImage, cv2.COLOR_GRAY2RGB)
        copyx = fake_rgb.copy()
        fake_gray = cv2.cvtColor(copyx, cv2.COLOR_BGR2GRAY)
        contours, hier = cv2.findContours(fake_gray, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
        blank_image2 = np.zeros((H, W, 3), np.uint8)

        blank_image2[:, :] = (255, 255, 255)
        blank_image3 = np.zeros((H, W, 3), np.uint8)

        blank_image3[:, :] = (255, 255, 255)
        # we are going to use a simple trick in there ...
        # if we know the font then it will be alot easier to calculate and get the contour according to font aspect ratio..
        # but it is a little messy..
        # so.. LETS take a ratio where our value is the overall ratio of common fonts..
        &#34;&#34;&#34;Arial        0.52
            Avant Garde         0.45
            Bookman     0.40
            Calibri     0.47
            Century Schoolbook  0.48
            Cochin      0.41
            Comic Sans  0.53
            Courier     0.43
            Courier New         0.42
            Garamond    0.38
            Georgia     0.48
            Helvetica   0.52
            Palatino    0.42
            Tahoma      0.55
            Times New Roman     0.45
            Trebuchet   0.52
            Verdana     0.58
            ------------------------------------
            W is messing with the calculations.. but wahtsoever.. their average is 0.471176470588235
            so it is 0,472
            but we are not looking all plates with birds eye.. and some of them are really messy..
             
            lets assume we are alooking with 45 degree.. (simple opengl calculations..) i m not forcing these calculations
            to be taken with all possible scenarios.. i m just calculating for 2 scenarios where width and height alone can change alot.. 
            then our 0.472 can become -&gt; w=472 h=1000 
                                            =&gt; rectangular area Height will increase 1000+472÷√2=1333,75
                                            =&gt; rectangular area WIDTH will drop to 472÷√2=333.75
                                            =&gt; so our 0.472 will become 0.25
            lets assume we are looking from a higher place where Height will look smaller.. lets assume again 45 degrees
                                        -&gt; w=472  h=1000
                                            =&gt; this time width will stay same..   472
                                            =&gt; heigh will change Angle ∠A = 22.5° = 22°30&#39;0&#34; = 0.3927 rad = π/8
                                                                Angle ∠B = 22.5° = 22°30&#39;0&#34; = 0.3927 rad = π/8
                                                                Angle ∠C = 135° = 2.35619 rad = 3/4π 
                                                                Side a = 541.1961
                                                                Side b = 541.1961
                                                                Side c = 1,000
                                                                
                                                                So our 0.472 will become to 472/541.19 =0.872
            so we will use 0.25 to 0.872
            -&gt; we should consider 1 more thing. first countours are not perfect because whatever we do to increase image quality there will be always nested contours
            or multiple chars to be accepted as one.. 
            so =&gt; first get image width into consideration.. with maximum minimum char count.. and find a proper orientation between them and newly calculated averages
            
            
            
            
            height/wiodth ratio
    ATTENTION !! this paart should be calculated with lots of samples.. in order to see perfect ratio
            
        
        &#34;&#34;&#34;

        for cnt in contours:
            if 200 &lt; cv2.contourArea(cnt) &lt; 5000:
                cv2.drawContours(self.prepared_img, [cnt], 0, (0, 255, 0), 2)
                cv2.drawContours(self.prepared_img, [cnt], 0, 255, -1)
                cv2.drawContours(fake_gray, [cnt], 0, (0, 255, 0), 2)
                cv2.drawContours(fake_gray, [cnt], 0, 255, -1)
                x, y, w, h = cv2.boundingRect(cnt)
                ROI = fake_rgb[y:y + h, x:x + w]
                cloneimg = ROI.copy()
                blank_image2[y:y + h, x:x + w] = cloneimg
        average_min=0.25
        average_max=0.872

        for cnt in contours:
            x, y, w, h = cv2.boundingRect(cnt)
            average = w/h


            if average_min &lt;= average &lt;= average_max :
                ROI = fake_rgb[y:y + h, x:x + w]
                cloneimg = ROI.copy()
                blank_image3[y:y + h, x:x + w] = cloneimg

        cv2.imwrite(&#34;/tmp/blank_image3&#34; + str(round(time.time() * 1000)) + &#34;.jpg&#34;, blank_image3)
        cv2.imwrite(&#34;/tmp/blank_image2&#34; + str(round(time.time() * 1000)) + &#34;.jpg&#34;, blank_image2)
        self.prepared_img = blank_image3

        self.base_img = img

        end1 = timer()
        self.each_img_process_time[imgx][&#34;prepare_end_&#34;] = end1
        self.MY_RESULTS[imgx][&#34;prepare_end_&#34;] = end1
    def prepareold_img(self,imgx):
        self.each_img_process_time[imgx] = {}
        start1 = timer()
        self.each_img_process_time[imgx][&#34;prepare_start_&#34;]=start1
        # process
        img = cv2.imread(imgx)

        #now try to resize ... remove noise...
        resize_test_license_plate = cv2.resize(
            img, None, fx=2, fy=2,
            interpolation=cv2.INTER_CUBIC)

        grayscale_resize_test_license_plate = cv2.cvtColor(
            resize_test_license_plate, cv2.COLOR_BGR2GRAY)

        gaussian_blur_license_plate = cv2.GaussianBlur(
            grayscale_resize_test_license_plate, (5, 5), 0)
        ret, imgf = cv2.threshold(gaussian_blur_license_plate, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
        gray = cv2.medianBlur(imgf, 3)
        imgf = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)


        self.prepared_img = imgf
        self.base_img=img

        end1 = timer()
        self.each_img_process_time[imgx][&#34;prepare_end&#34;] =end1

    def prepare(self):
        start = timer()
        self.prepare_start_time = start
        self.MY_RESULTS[&#34;prepare_start&#34;] = start

        end = timer()
        self.prepare_end_time = end
        self.MY_RESULTS[&#34;prepare_end&#34;] = end

    def start_(self, imgx):
        start1 = timer()
        self.each_img_process_time[imgx][&#34;_start&#34;] = start1
        self.MY_RESULTS[imgx][&#34;_start&#34;] = start1
        # process
        base2 = self.base_img.copy()
        hsv = cv2.cvtColor(base2, cv2.COLOR_BGR2HSV)
        lower = np.array(np.array([0,0,0], dtype=np.uint8), dtype=&#34;uint8&#34;)
        upper = np.array(np.array([0,0,255], dtype=np.uint8), dtype=&#34;uint8&#34;)

        # find the colors within the specified boundaries and apply
        # the mask
        mask = cv2.inRange(hsv, lower, upper)
        output = cv2.bitwise_and(base2, base2, mask=mask)

        ret, thresh = cv2.threshold(mask, 40, 255, 0)
        contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

        if len(contours) != 0:
            # draw in blue the contours that were founded
            cv2.drawContours(output, contours, -1, 255, 3)

            # find the biggest countour (c) by the area
            c = max(contours, key=cv2.contourArea)
            x, y, w, h = cv2.boundingRect(c)

            # draw the biggest contour (c) in green
            cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 2)

        #cv2.imwrite(imgx.replace(&#39;/img/&#39;,(&#39;/outputs/&#39;+str(self.my_info[&#34;name&#34;]))+&#34;/&#34;),output)
        predicted_result = pytesseract.image_to_string(self.prepared_img, lang=&#39;eng&#39;,
                                                       config=&#39;--oem 1 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&#39;)

        filter_predicted_result = &#34;&#34;.join(predicted_result.split()).replace(&#34;:&#34;, &#34;&#34;).replace(&#34;-&#34;, &#34;&#34;).replace(&#34;_&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
        cleared_text = clear_text(filter_predicted_result)
        self.MY_RESULTS[imgx][&#34;result&#34;] = cleared_text
        self.MY_RESULTS[imgx][&#34;dirty_result&#34;] = filter_predicted_result

        #print(imgx + &#34; -&gt; &#34; + pytesseract.image_to_string(self.prepared_img))
        cv2.imwrite(imgx.replace(&#39;/img/&#39;, (&#39;/outputs/&#39; + str(self.my_info[&#34;name&#34;])) + &#34;/&#34;), output)
        Statics.LOGGER.logme(str(self.__class__.__name__)+&#34; &#34;+imgx+ &#34; -&gt; &#34;+filter_predicted_result)

        end1 = timer()
        self.each_img_process_time[imgx][&#34;_end&#34;] = end1
        self.MY_RESULTS[imgx][&#34;_end&#34;] = end1



    def find_score(self, arr, angle):
        data = inter.rotate(arr, angle, reshape=False, order=0)
        hist = np.sum(data, axis=1)
        score = np.sum((hist[1:] - hist[:-1]) ** 2)
        return hist,  1</code></pre>
</details>
<h3>Class variables</h3>
<dl>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.MY_RESULTS"><code class="name">var <span class="ident">MY_RESULTS</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.base_img"><code class="name">var <span class="ident">base_img</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.default_height"><code class="name">var <span class="ident">default_height</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.default_width"><code class="name">var <span class="ident">default_width</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.each_img_process_time"><code class="name">var <span class="ident">each_img_process_time</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.end_time"><code class="name">var <span class="ident">end_time</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.min_confidence"><code class="name">var <span class="ident">min_confidence</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.model_usage"><code class="name">var <span class="ident">model_usage</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.my_info"><code class="name">var <span class="ident">my_info</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.mymodels"><code class="name">var <span class="ident">mymodels</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.newlinux"><code class="name">var <span class="ident">newlinux</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepare_end_time"><code class="name">var <span class="ident">prepare_end_time</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepare_start_time"><code class="name">var <span class="ident">prepare_start_time</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepared_img"><code class="name">var <span class="ident">prepared_img</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.rH"><code class="name">var <span class="ident">rH</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.rW"><code class="name">var <span class="ident">rW</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.retrain"><code class="name">var <span class="ident">retrain</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.run"><code class="name">var <span class="ident">run</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.start_time"><code class="name">var <span class="ident">start_time</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.using_gpu"><code class="name">var <span class="ident">using_gpu</span></code></dt>
<dd>
<div class="desc"></div>
</dd>
</dl>
<h3>Methods</h3>
<dl>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.check_deps"><code class="name flex">
<span>def <span class="ident">check_deps</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def check_deps(self):
    # first check version of linux.
    str = lsb_release.get_lsb_information()
    release=str[&#34;RELEASE&#34;]
    if release.startswith(&#34;18&#34;) or release.starsWith(&#34;19&#34;) or release.startsWith(&#34;20&#34;):
        self.newlinux=1
    # first check if tesseract is installed..
    return_data=&#34;&#34;
    try_to_install=0
    try :
        result = subprocess.run([&#39;tesseract&#39;, &#39;-v&#39;], stdout=subprocess.PIPE)
        return_data=result.stdout
        if return_data.find(&#34;not found&#34;) &gt; -1 or return_data.find(&#34;No such file or directory&#34;) &gt; -1 :
            try_to_install=1
    except:
        try_to_install=1

    if try_to_install == 1 :
        # tesseract is not installed
        if self.newlinux == 1:
            # can install with apt-get
            check_call([&#39;apt-get&#39;, &#39;install&#39;, &#39;-y&#39;, &#39;tesseract-ocr&#39;],
                       stdout=open(os.devnull, &#39;wb&#39;), stderr=STDOUT)
        else :
            check_call([ &#39;add-apt-repository&#39;,  &#39;-y&#39;, &#39;ppa:alex-p/tesseract-ocr&#39;],
                       stdout=open(os.devnull, &#39;wb&#39;), stderr=STDOUT)
            check_call([ &#39;apt-get&#39;, &#39;update&#39;],
                       stdout=open(os.devnull, &#39;wb&#39;), stderr=STDOUT)
            check_call([ &#39;apt-get&#39;, &#39;install&#39;, &#39;-y&#39;, &#39;tesseract-ocr&#39;],
                       stdout=open(os.devnull, &#39;wb&#39;), stderr=STDOUT)
    try:
        output_folder_name = &#39;INPUT_OUTPUT/outputs/&#39; + str(self.__class__.__name__)
        os.makedirs(output_folder_name)
    except OSError as e:
        Statics.LOGGER.logme(str(self.__class__.__name__)+&#34; &#34;+str(e))</code></pre>
</details>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.end_main_timer"><code class="name flex">
<span>def <span class="ident">end_main_timer</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def end_main_timer(self):
    end = timer()
    self.end_time = end
    self.MY_RESULTS[&#34;main_timer_end&#34;] = end</code></pre>
</details>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.find_score"><code class="name flex">
<span>def <span class="ident">find_score</span></span>(<span>self, arr, angle)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def find_score(self, arr, angle):
    data = inter.rotate(arr, angle, reshape=False, order=0)
    hist = np.sum(data, axis=1)
    score = np.sum((hist[1:] - hist[:-1]) ** 2)
    return hist,  1</code></pre>
</details>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepare"><code class="name flex">
<span>def <span class="ident">prepare</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare(self):
    start = timer()
    self.prepare_start_time = start
    self.MY_RESULTS[&#34;prepare_start&#34;] = start

    end = timer()
    self.prepare_end_time = end
    self.MY_RESULTS[&#34;prepare_end&#34;] = end</code></pre>
</details>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepare_img"><code class="name flex">
<span>def <span class="ident">prepare_img</span></span>(<span>self, imgx)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepare_img(self, imgx):
    self.each_img_process_time[imgx] = {}
    self.MY_RESULTS[imgx] = {}
    start1 = timer()
    self.each_img_process_time[imgx][&#34;prepare_start_&#34;] = start1
    self.MY_RESULTS[imgx][&#34;prepare_start_&#34;] = start1
    # process
    img = cv2.imread(imgx)
    self.base_img = cv2.imread(imgx)
    orig = self.base_img.copy()
    # image_resized = cv2.resize(orig,width=320,interpolation=cv2.INTER_CUBIC)
    image_resized =  image_resize(orig, width=320)
    (H, W) = image_resized.shape[:2]

    # set the new width and height and then determine the ratio in change
    # for both the width and height
    blank_image = cv2.fastNlMeansDenoisingColored(image_resized, None, 10, 10, 7, 21)
    # blank_image= cv2.adaptiveThreshold(blank_image, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 31, 2)
    img_gray = cv2.cvtColor(blank_image, cv2.COLOR_BGR2GRAY)
    img_blur = cv2.medianBlur(img_gray, 5)
    img_thresh_Gaussian = cv2.adaptiveThreshold(img_blur, 255,
                                                cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)
    (thresh, blackAndWhiteImage) = cv2.threshold(img_thresh_Gaussian, 127, 255, cv2.THRESH_BINARY)

    # kernel = np.array([[-1, -1, -1], [-1, 9, -1], [-1, -1, -1]])
    # self.prepared_img = cv2.filter2D(blank_image, -1, kernel)
    # self.prepared_img = cv2.cvtColor(self.prepared_img, cv2.COLOR_BGR2GRAY)

    fake_rgb = cv2.cvtColor(blackAndWhiteImage, cv2.COLOR_GRAY2RGB)
    copyx = fake_rgb.copy()
    fake_gray = cv2.cvtColor(copyx, cv2.COLOR_BGR2GRAY)
    contours, hier = cv2.findContours(fake_gray, cv2.RETR_LIST, cv2.CHAIN_APPROX_SIMPLE)
    blank_image2 = np.zeros((H, W, 3), np.uint8)

    blank_image2[:, :] = (255, 255, 255)
    blank_image3 = np.zeros((H, W, 3), np.uint8)

    blank_image3[:, :] = (255, 255, 255)
    # we are going to use a simple trick in there ...
    # if we know the font then it will be alot easier to calculate and get the contour according to font aspect ratio..
    # but it is a little messy..
    # so.. LETS take a ratio where our value is the overall ratio of common fonts..
    &#34;&#34;&#34;Arial        0.52
        Avant Garde         0.45
        Bookman     0.40
        Calibri     0.47
        Century Schoolbook  0.48
        Cochin      0.41
        Comic Sans  0.53
        Courier     0.43
        Courier New         0.42
        Garamond    0.38
        Georgia     0.48
        Helvetica   0.52
        Palatino    0.42
        Tahoma      0.55
        Times New Roman     0.45
        Trebuchet   0.52
        Verdana     0.58
        ------------------------------------
        W is messing with the calculations.. but wahtsoever.. their average is 0.471176470588235
        so it is 0,472
        but we are not looking all plates with birds eye.. and some of them are really messy..
         
        lets assume we are alooking with 45 degree.. (simple opengl calculations..) i m not forcing these calculations
        to be taken with all possible scenarios.. i m just calculating for 2 scenarios where width and height alone can change alot.. 
        then our 0.472 can become -&gt; w=472 h=1000 
                                        =&gt; rectangular area Height will increase 1000+472÷√2=1333,75
                                        =&gt; rectangular area WIDTH will drop to 472÷√2=333.75
                                        =&gt; so our 0.472 will become 0.25
        lets assume we are looking from a higher place where Height will look smaller.. lets assume again 45 degrees
                                    -&gt; w=472  h=1000
                                        =&gt; this time width will stay same..   472
                                        =&gt; heigh will change Angle ∠A = 22.5° = 22°30&#39;0&#34; = 0.3927 rad = π/8
                                                            Angle ∠B = 22.5° = 22°30&#39;0&#34; = 0.3927 rad = π/8
                                                            Angle ∠C = 135° = 2.35619 rad = 3/4π 
                                                            Side a = 541.1961
                                                            Side b = 541.1961
                                                            Side c = 1,000
                                                            
                                                            So our 0.472 will become to 472/541.19 =0.872
        so we will use 0.25 to 0.872
        -&gt; we should consider 1 more thing. first countours are not perfect because whatever we do to increase image quality there will be always nested contours
        or multiple chars to be accepted as one.. 
        so =&gt; first get image width into consideration.. with maximum minimum char count.. and find a proper orientation between them and newly calculated averages
        
        
        
        
        height/wiodth ratio
ATTENTION !! this paart should be calculated with lots of samples.. in order to see perfect ratio
        
    
    &#34;&#34;&#34;

    for cnt in contours:
        if 200 &lt; cv2.contourArea(cnt) &lt; 5000:
            cv2.drawContours(self.prepared_img, [cnt], 0, (0, 255, 0), 2)
            cv2.drawContours(self.prepared_img, [cnt], 0, 255, -1)
            cv2.drawContours(fake_gray, [cnt], 0, (0, 255, 0), 2)
            cv2.drawContours(fake_gray, [cnt], 0, 255, -1)
            x, y, w, h = cv2.boundingRect(cnt)
            ROI = fake_rgb[y:y + h, x:x + w]
            cloneimg = ROI.copy()
            blank_image2[y:y + h, x:x + w] = cloneimg
    average_min=0.25
    average_max=0.872

    for cnt in contours:
        x, y, w, h = cv2.boundingRect(cnt)
        average = w/h


        if average_min &lt;= average &lt;= average_max :
            ROI = fake_rgb[y:y + h, x:x + w]
            cloneimg = ROI.copy()
            blank_image3[y:y + h, x:x + w] = cloneimg

    cv2.imwrite(&#34;/tmp/blank_image3&#34; + str(round(time.time() * 1000)) + &#34;.jpg&#34;, blank_image3)
    cv2.imwrite(&#34;/tmp/blank_image2&#34; + str(round(time.time() * 1000)) + &#34;.jpg&#34;, blank_image2)
    self.prepared_img = blank_image3

    self.base_img = img

    end1 = timer()
    self.each_img_process_time[imgx][&#34;prepare_end_&#34;] = end1
    self.MY_RESULTS[imgx][&#34;prepare_end_&#34;] = end1</code></pre>
</details>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepareold_img"><code class="name flex">
<span>def <span class="ident">prepareold_img</span></span>(<span>self, imgx)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def prepareold_img(self,imgx):
    self.each_img_process_time[imgx] = {}
    start1 = timer()
    self.each_img_process_time[imgx][&#34;prepare_start_&#34;]=start1
    # process
    img = cv2.imread(imgx)

    #now try to resize ... remove noise...
    resize_test_license_plate = cv2.resize(
        img, None, fx=2, fy=2,
        interpolation=cv2.INTER_CUBIC)

    grayscale_resize_test_license_plate = cv2.cvtColor(
        resize_test_license_plate, cv2.COLOR_BGR2GRAY)

    gaussian_blur_license_plate = cv2.GaussianBlur(
        grayscale_resize_test_license_plate, (5, 5), 0)
    ret, imgf = cv2.threshold(gaussian_blur_license_plate, 0, 255, cv2.THRESH_BINARY | cv2.THRESH_OTSU)
    gray = cv2.medianBlur(imgf, 3)
    imgf = cv2.adaptiveThreshold(gray, 255, cv2.ADAPTIVE_THRESH_GAUSSIAN_C, cv2.THRESH_BINARY, 11, 2)


    self.prepared_img = imgf
    self.base_img=img

    end1 = timer()
    self.each_img_process_time[imgx][&#34;prepare_end&#34;] =end1</code></pre>
</details>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.return_dict_with_results"><code class="name flex">
<span>def <span class="ident">return_dict_with_results</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def return_dict_with_results(self):
    return self.my_info</code></pre>
</details>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.return_my_dict"><code class="name flex">
<span>def <span class="ident">return_my_dict</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def return_my_dict(self):
    return self.my_info</code></pre>
</details>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.start_"><code class="name flex">
<span>def <span class="ident">start_</span></span>(<span>self, imgx)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def start_(self, imgx):
    start1 = timer()
    self.each_img_process_time[imgx][&#34;_start&#34;] = start1
    self.MY_RESULTS[imgx][&#34;_start&#34;] = start1
    # process
    base2 = self.base_img.copy()
    hsv = cv2.cvtColor(base2, cv2.COLOR_BGR2HSV)
    lower = np.array(np.array([0,0,0], dtype=np.uint8), dtype=&#34;uint8&#34;)
    upper = np.array(np.array([0,0,255], dtype=np.uint8), dtype=&#34;uint8&#34;)

    # find the colors within the specified boundaries and apply
    # the mask
    mask = cv2.inRange(hsv, lower, upper)
    output = cv2.bitwise_and(base2, base2, mask=mask)

    ret, thresh = cv2.threshold(mask, 40, 255, 0)
    contours, hierarchy = cv2.findContours(thresh, cv2.RETR_EXTERNAL, cv2.CHAIN_APPROX_NONE)

    if len(contours) != 0:
        # draw in blue the contours that were founded
        cv2.drawContours(output, contours, -1, 255, 3)

        # find the biggest countour (c) by the area
        c = max(contours, key=cv2.contourArea)
        x, y, w, h = cv2.boundingRect(c)

        # draw the biggest contour (c) in green
        cv2.rectangle(output, (x, y), (x + w, y + h), (0, 255, 0), 2)

    #cv2.imwrite(imgx.replace(&#39;/img/&#39;,(&#39;/outputs/&#39;+str(self.my_info[&#34;name&#34;]))+&#34;/&#34;),output)
    predicted_result = pytesseract.image_to_string(self.prepared_img, lang=&#39;eng&#39;,
                                                   config=&#39;--oem 1 --psm 6 -c tessedit_char_whitelist=ABCDEFGHIJKLMNOPQRSTUVWXYZ0123456789&#39;)

    filter_predicted_result = &#34;&#34;.join(predicted_result.split()).replace(&#34;:&#34;, &#34;&#34;).replace(&#34;-&#34;, &#34;&#34;).replace(&#34;_&#34;, &#34;&#34;).replace(&#34; &#34;, &#34;&#34;)
    cleared_text = clear_text(filter_predicted_result)
    self.MY_RESULTS[imgx][&#34;result&#34;] = cleared_text
    self.MY_RESULTS[imgx][&#34;dirty_result&#34;] = filter_predicted_result

    #print(imgx + &#34; -&gt; &#34; + pytesseract.image_to_string(self.prepared_img))
    cv2.imwrite(imgx.replace(&#39;/img/&#39;, (&#39;/outputs/&#39; + str(self.my_info[&#34;name&#34;])) + &#34;/&#34;), output)
    Statics.LOGGER.logme(str(self.__class__.__name__)+&#34; &#34;+imgx+ &#34; -&gt; &#34;+filter_predicted_result)

    end1 = timer()
    self.each_img_process_time[imgx][&#34;_end&#34;] = end1
    self.MY_RESULTS[imgx][&#34;_end&#34;] = end1</code></pre>
</details>
</dd>
<dt id="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.start_main_timer"><code class="name flex">
<span>def <span class="ident">start_main_timer</span></span>(<span>self)</span>
</code></dt>
<dd>
<div class="desc"></div>
<details class="source">
<summary>
<span>Expand source code</span>
</summary>
<pre><code class="python">def start_main_timer(self):
    start = timer()
    self.start_time = start
    self.MY_RESULTS[&#34;main_timer_start&#34;] = start</code></pre>
</details>
</dd>
</dl>
</dd>
</dl>
</section>
</article>
<nav id="sidebar">
<h1>Index</h1>
<div class="toc">
<ul></ul>
</div>
<ul id="index">
<li><h3>Super-module</h3>
<ul>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract" href="index.html">HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract</a></code></li>
</ul>
</li>
<li><h3><a href="#header-classes">Classes</a></h3>
<ul>
<li>
<h4><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract">TestTesseract</a></code></h4>
<ul class="">
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.MY_RESULTS" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.MY_RESULTS">MY_RESULTS</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.base_img" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.base_img">base_img</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.check_deps" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.check_deps">check_deps</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.default_height" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.default_height">default_height</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.default_width" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.default_width">default_width</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.each_img_process_time" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.each_img_process_time">each_img_process_time</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.end_main_timer" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.end_main_timer">end_main_timer</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.end_time" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.end_time">end_time</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.find_score" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.find_score">find_score</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.min_confidence" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.min_confidence">min_confidence</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.model_usage" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.model_usage">model_usage</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.my_info" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.my_info">my_info</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.mymodels" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.mymodels">mymodels</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.newlinux" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.newlinux">newlinux</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepare" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepare">prepare</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepare_end_time" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepare_end_time">prepare_end_time</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepare_img" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepare_img">prepare_img</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepare_start_time" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepare_start_time">prepare_start_time</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepared_img" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepared_img">prepared_img</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepareold_img" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.prepareold_img">prepareold_img</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.rH" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.rH">rH</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.rW" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.rW">rW</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.retrain" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.retrain">retrain</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.return_dict_with_results" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.return_dict_with_results">return_dict_with_results</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.return_my_dict" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.return_my_dict">return_my_dict</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.run" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.run">run</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.start_" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.start_">start_</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.start_main_timer" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.start_main_timer">start_main_timer</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.start_time" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.start_time">start_time</a></code></li>
<li><code><a title="HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.using_gpu" href="#HasanSARMAN_PLAKA_OKUMA.modules.TestTesseract.TestTesseract.TestTesseract.using_gpu">using_gpu</a></code></li>
</ul>
</li>
</ul>
</li>
</ul>
</nav>
</main>
<footer id="footer">
<p>Generated by <a href="https://pdoc3.github.io/pdoc"><cite>pdoc</cite> 0.9.2</a>.</p>
</footer>
</body>
</html>